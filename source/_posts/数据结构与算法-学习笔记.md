---
title: 数据结构与算法 学习笔记
date: 2019-03-31 16:40:07
tags: DATASTRUCTURE, ALGORITHM
categories: Tech
---

## 开始

{% asset_img 01.jpg %}

## 复杂度分析

<!-- more -->

T(n) = O(f(n))
T(n)：代码执行的时间
n: 数据规模的大小
f(n): 每行代码执行的次数总和
O: 表示代码执行时间T(n)与f(n)表达式成正比

大O时间复杂度表示法：表示代码执行时间随数据规模增大的变化趋势
也叫做渐进时间复杂度，简称时间复杂度

当n很大时，公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。只需要记录一个最大量级
eg 可以记为 T(n) = O(n), T(n) = O(n^2)

### 时间复杂度分析

如何分析一段代码的时间复杂度

方法1 只关注循环次数最多的一段代码 

方法2 加法法则：总复杂度等于量级最大的那段代码的复杂度
如果 T1(n) = O(f(n))，T2(n) = O(g(n))；那么T(n) = T1(n) + T2(n) = max(O(f(n)), O(g(n))) = max(O(f(n), g(n)))

方法3 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
如果 T1(n) = O(f(n)), T2(n) = O(g(n)); 那么T(n) = T1(n) * T2(n) = O(f(n)) * O(g(n)) = O(f(n) * g(n))
也就是说，假设T1(n) = O(n), T2(n) = O(n^2), 则 T1(n) * T2(n) = O(n^3)

几种常见的时间复杂度

{% asset_img 02.jpg %}

分为多项式量级和非多项式量级，非多项式量级只有两个：O(2^n)和O(n!)
当数据规模越来越大时，非多项式量级算法的执行时间会急剧增加

O(logn): 对数之间是可以互相转换的，比如log3n = log32 * log2n, 所以O(log3n) = O(C * log2n), 所以O(log2n)等于O(log3n)。因此在对数时间复杂度的表示方法里，忽略对数的底，统一表示为O(logn)

当复杂度由两个数据规模来决定：无法确定两个数据规模谁的量极大，因此不能忽略，加法法则不生效，T1(m) + T2(n) = O(f(m) + g(n)). 乘法法则继续有效，T1(m) * T2(n) = O(f(m) * f(n))

{% asset_img 03.jpg %}

### 最好、最坏、平均、均摊时间复杂度

最好时间复杂度：在最理想的情况下，执行这段代码的时间复杂度
最坏时间复杂度：在最糟糕的情况下，执行这段代码的时间复杂度
平均情况时间复杂度：加权平均时间复杂度 或者 期望时间复杂度
均摊时间复杂度：在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结果就等于低级别复杂度

## 空间复杂度分析

空间复杂度全称为渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系

常见的空间复杂度就是O(1), O(n), O(n^2)

## 数组

数组是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据

线性表：每个线性表上的数据最多只有前和后两个方向。（数组，链表，队列，栈）

{% asset_img 04.jpg %}

非线性表：

{% asset_img 05.jpg %}

连续的内存空间和相同类型的数据：实现了随机访问

当需要随机访问数组中的某个元素时，会首先通过寻址，计算出该元素存储的内存地址

```
a[i]_address = base_address + i * data_type_size
```

数据插入、删除的时间复杂度为O(N)

## 链表

通过指针将一组零散的内存块串联起来使用

{% asset_img 06.jpg %}

### 单链表

{% asset_img 07.jpg %}

头结点：用来记录链表的基地址
尾结点：指针指向一个空地址NULL，表示这是链表上的最后一个节点

插入和删除：
{% asset_img 08.jpg %}

访问数据需要进行依次遍历

### 循环链表

{% asset_img 09.jpg %}

优点：从链尾到链头比较方便，当有处理的数据具有环形结构特点时，适合采用

### 双向链表

{% asset_img 10.jpg %}

双向链表较单向链表的优势：
- 在删除给定指针指向的节点，或者在某个指定节点前插入一个节点的时候，不需要重新遍历，时间复杂度为O(1)
- 当链表为有序链表时，可以记录上次查找的位置p，每次查询时，根据目标值和p的大小关系，决定向前还是向后查找

扩展阅读：LinkedHashMap

### 双向循环列表

{% asset_img 11.jpg %}


## 链表代码编写

指针：将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针。或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量

p->next = q
p节点中的next指针存储了q节点的内存地址

p->next = p->next->next
p节点的next指针存储了p节点的下下一个节点的内存地址

针对链表的插入、删除操作，需要对插入第一个节点和删除最后一个节点的情况进行特殊处理
改进：哨兵机制。引入哨兵节点，不存储数据（带头链表）

{% asset_img 12.jpg %}

重点留意边界条件的处理
- 链表为空时
- 链表只包含一个节点时
- 链表只包含两个节点时
- 代码逻辑在处理头结点和尾节点的时候

其他技巧：
- 举例法、画图法
- 多写多练

## 栈

两个操作：入栈和出栈

栈既可以用数组实现，也可以用链表实现

## 队列

操作受限的线性表结构

先进者先出

两个基本操作：入队(enqueue)和出队(enqueue)

{% asset_img 13.jpg %}

### 额外特性的队列

循环队列、阻塞队列、并发队列

### 顺序队列和链式队列

- 顺序队列：数组实现
- 链式队列：链表实现

### 循环队列

队空的判断条件：head == tail
队满的判断条件：(tail + 1) % n == head

## 递归

### 递归需要满足的三个条件

- 一个问题的解可以分解为几个子问题的解
- 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样
- 存在递归终止条件

### 如何编写递归代码

写出递归公式，找到终止条件，将递归公式转换为代码

关键：找到如何将大问题分解为小问题的规律，并且基于此规律写出地推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码
（不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤）

### 警惕重复计算

为了避免重复计算，可以通过一个数据结构来保存已经求结果的f(k), 当递归调用到f(k)时，先看下是否已经求解过了，如果是，则直接取值返回，不需要重复计算

### 将递归代码改为非递归代码

略


## 排序

{% asset_img 14.jpg %}

### 如何分析一个排序算法

#### 排序算法的执行效率

- 最好情况、最坏情况、平均情况时间复杂度
分别给出最好情况、最坏情况、平均情况下的时间复杂度。最好、最坏时间复杂度对应的要排序的原始数据是什么样的

- 时间复杂度的系数、常数、低阶
排序的可能是规模很小的数据，所以需要把系数、常数、低阶也考虑进来

- 比较次数和交换（或移动）次数

#### 排序算法的内存消耗

针对排序算法的空间复杂度，还引入了一个新的概念，原地排序。
原地排序算法：特指空间复杂度为O(1)的排序算法

#### 排序算法的稳定性

稳定性：如果待排的序列中存在值相等的元素，经过排序之后，相等元素之间原有的顺序不变

### 冒泡排序

冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让他俩互换。一次冒泡会让至少一个元素移动到他应该在的位置，重复n次，就完成了n个数据的排序工作

eg [4, 5, 6, 3, 2, 1]

第一次冒泡：
{% asset_img 15.jpg %}

一次冒泡之后，6已经移动到了正确的位置上。要想完成所有数据的排序，只需要进行6次这样的冒泡操作

{% asset_img 16.jpg %}

优化点：
当某次冒泡操作没有数据交换，说明已经达到完全有序，不用继续执行后续的冒泡操作了

- 是否为原地排序
是，只涉及相邻元素的交换操作，只需要常量级的临时空间

- 是否为稳定的排序算法
是

- 时间复杂度
最好情况：所有元素已经有序，只需要做一次冒泡，为O(N)
最坏情况：元素是倒序排列的，需要进行n次冒泡，为O(N^2)
平均情况：O(N^2)

### 插入排序

{% asset_img 17.jpg %}

是一个动态排序的过程，动态地向有序数组中插入元素，保持结合的一直有序

将数组分为两个区间，已排序区间和未排序区间。初始已排序区间只有第一个元素。取未排序区间中的元素，在已排序区间中找到合适的位置插入，并保证已排序区间一直有序。重复这个过程直到未排序区间元素为空

{% asset_img 18.jpg %}

插入排序也包含两种操作：元素的比较和移动

对于不同的查找插入方法（从头到尾、从尾到头），元素的比较次数是有区别的。但对于一个给定的初始序列，移动操作的次数总是固定的，就等于逆序度

{% asset_img 19.jpg %}

- 是否为原地排序
是 

- 是否为稳定的排序算法
是（可以将后面出现的元素插入到前面出现元素的后面）

- 时间复杂度
最好情况：所有元素有序，不需要搬移任何数据，为O(N)
最坏情况：倒序，每次插入相当于在数组的第一个位置插入新的数据，为O(N^2)
平均情况：每次插入操作相当于在数组中插入一条数据，循环执行n次插入操作，O(N^2)

## 选择排序

也分为已排序区间和未排序区间。选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾

{% asset_img 20.jpg %}

- 是否为原地排序
是

- 是否为稳定的排序算法
否（eg 5, 8, 5, 2, 9 --- 第一次找到2，和第一个5交换位置，之后第一个5和中间的5的顺序就变了）

- 时间复杂度
最好情况：O(N^2)
最坏情况：O(N^2)
平均情况：O(N^2)

{% asset_img 21.jpg %}


## 归并排序 Merge Sort

分治思想：先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了

> 分而治之，将一个大问题分解成小的子问题来解决
> 和递归思想类似

{% asset_img 22.jpg %}

归并排序的递推公式

递推公式：merge_sort(p...r) = merge(merge_sort(p...q), merge_sort(q+1...r))
终止条件：p >= r 不用再继续分解

merge_sort(p...r) 表示，给下标从p到r的数组排序。我们将这个问题转化为了两个子问题，merge_sort(p...q)和merge_sort(q+1...r), 其中下标q等于p和r的中间位置，也就是(p+r)/2。当下标从p到q和从q+1到r这两个子数组都排好之后，再将两个有序的子数组合并到一起，这样下标从p到r之间的数据也就排好了

### merge操作

申请一个临时的数组tmp，大小与A[p...r]相同，用两个游标i, j，分别指向A(p...q)和A(q+1...r)的第一个元素，比较A[i]和A[j]，如果A[i] < A[j], 把A[i]放到临时数组tmp，并把i后移一位，否则将A[j]放到tmp，并把j后移一位

继续上述过程，直到其中一个子数组的所有数据都放入tmp中，再把另一个数组中的数据依次加入到临时数组的末尾，这个时候，临时数组中存储的就是两个子数组合并之后的结果了。最后再把tmp中的数据拷贝到原数组中

{% asset_img 23.jpg %}

- 是否为稳定的排序算法
是，merge操作的时候，当遇到值相同的两个元素时，优先放第一个子数组的元素

- 时间复杂度
最好、最坏、平均：O(nlogn)

时间复杂度递推关系式：T(a) = T(b) + T(c) + K
K: 两个子问题b，c的结果合并成a的结果所消耗的时间

> 递归代码的时间复杂度也可以写成递推公式

T(a) = T(b) + T(c) + K
T(1) = C

T(n) = 2*T(n/2) + n
= 2*T(n/2) + n
= 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n
= 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n
....
= 2^k * T(n/2^k) + k*n

当T(n/2^k) = T(1)时，也就是n/2^k=1，得到k=log2n, 因此T(n) = Cn + nlog2n
即T(n) = O(nlogn)

- 是否为原地排序
否，O(N)

## 快速排序

选择p到r之间的任意一个数据作为pivot（分区点）
遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将pivot放到中间。经过这步之后，p到r之间的数据被分成了三个部分

{% asset_img 24.jpg %}

递归排序，直到区间缩小为1，就说明所有的数据都有序了

递推公式
quick_sort(p...r) = quick_sort(p...q-1) + quick_sort(q+1, r)
终止条件
p >= r

### partation操作

通过游标i把p...r-1分成两部分。p...i-1的元素都是小于pivot的，叫做”已处理区间“, i...r-1叫做”未处理区间“
每次从未处理区间取一个元素A[j], 与pivot对比，如果小于pivot，则将其加入到已处理区间的尾部

插入时，为了避免搬移数据，只需要将A[i]与A[j]交换

{% asset_img 25.jpg %}

- 是否为稳定的排序算法
否

- 是否为原地排序
是

- 时间复杂度
最好、平均：O(NlogN)
最坏：O(N^2)

## 桶排序

将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了

{% asset_img 26.jpg %}

#### 数据要求
- 要排序的数据很容易就能划分成n个桶，并且桶与桶之间有着天然的大小顺序
- 数据在各个桶之间的分布是比较均匀的
- 比较适合用在外部排序中

## 计数排序

桶排序的一种特殊情况
当要排序的n个数据，所处的范围并不大的时候，比如最大值是k，可以把数据分为k个桶，每个桶内的数据值都是相同的，省掉了桶内排序的时间

只能用在数据范围不大的场景中，如果数据范围k比要排序的数据n大很多，就不适合用技术排序了。而且，技术排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数

## 基数排序

假设要比较两个手机号码a，b的大小，如果在前面几位中，a号码已经比b号码大了，那后面的几位就不用看了

借助稳定排序算法，先按照最后一位来排序手机号码，然后再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过11次排序之后，手机号码就都有序了

按照每位来排序的排序算法要求是稳定的

{% asset_img 27.jpg %}

根据每一位来排序，可以用桶排序或计数排序

有时要排序的数据并不都是等长的，可以吧所有的数据补齐到相同的长度，位数不够的可以补‘0’（ASCII中所有字母都大于‘0’）

基数排序对数据需要可以分割出独立的”位“来比较，而且位之间有递进的关系，如果a数据的高位比b数据大，那剩下的低位就不用比较了。此外，每一位的数据范围不能太大，要可以使用线性排序算法来排序，否则基数排序的时间复杂度无法做到O(N)

## 如何实现一个通用的、高性能的排序算法

### 如何选择合适的排序算法

{% asset_img 28.jpg %}

### 如何优化快速排序

快排出现O(N^2)的情况：数据有序或接近有序，每次分区点都选在最后一个数据。（分区点选择不合理）

理想的区分点：被分区点分开的两个区间中，数据的数量差不多

#### 分区方法

I. 三数取中法

从区间的首、尾、中取三个数字，对比大小，取中间大小的元素作为分区点
（如果需要排序的数组比较大，可能需要更多的数字进行取中）

II. 随机法

在区间中随机选择元素作为分区点


## 二分查找

二分查找针对的是一个有序的数据集合，每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，知道找到要查找的元素，或者区间被缩小为0

时间复杂度：O(longn)

### 二分查找注意点

1 循环退出条件

low <= high

2 mid的取值

mid=(low+high)/2可能有问题，如果low和high比较大的话，两个之和可能溢出。改进方式为log+(high-low)/2。如果要将性能优化到极致的话，可以将除以2操作转化成位运算low+((high-low)>>1)

3 low和high的更新

low = mid+1, high = mid-1
如果直接写成low=high或high=mid，可能发生死循环。比如high=3, low=3使，如果a[3]不等于value的情况

### 二分查找变形问题

{% asset_img 29.jpg %}


## 跳表

有序链表+多级索引的结构

空间换时间的设计思路

{% asset_img 30.jpg %}

### 时间复杂度

每两个结点会抽出一个结点作为上一级索引的结点
第一级索引的结点个数大约为n/2，第二级结点个数为n/4，第三级n/8………第k级为n/(2^k)

假设索引有h级，最高级的索引有2个结点。通过上面的公式可得n/2^h=2, 所以h=log2n-1，如果包含原始链表这一层，h=log2n
如果在跳表中查询某个数据的时候，如果每一层都要遍历m个节点，查询一个数据的时间复杂度是O(m*logn)
m最多为3：每层索引的相邻结点对应下一层索引的结点范围数量不超过3

{% asset_img 31.jpg %}

### 空间复杂度

{% asset_img 32.jpg %}
O(n): n/2+n/4+n/8+……+n/(2^k)+……+8+4+2=n-2

### 插入和删除

时间复杂度：O(logn)

插入：
{% asset_img 33.jpg %}

删除：
如果这个结点在索引中也有出现，除了要删除原始链表的结点，还要删除索引中的

### 跳表索引动态更新

维护索引与原始链表大小之间的平衡

通过随机函数，决定这个结点插入到哪几级索引中，比如随机函数生成了值K，那么就将这个结点添加到第一级到第K级这几个索引中

{% asset_img 34.jpg %}

## 散列表 Hash Table

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表是数组的一种扩展，由数组演化而来

{% asset_img 35.jpg %}

### 散列函数

散列函数设计的基本要求
- 散列函数计算得到的散列值是一个非负整数
- 如果key1 == key2, 那么hash(key1) == hash(key2)
- 如果key1 != key2, 那么hash(key1) != hash(key2)

### 散列冲突

解决散列冲突 

**1 开放寻址法**

如果出现了散列冲突，就重新探测一个空闲位置，将其插入

线性探测：
如果当前位置已经被占用，就从当前位置开始依次向后查找，直到找到空闲位置
删除：将删除的元素特殊标记为deleted

二次探测:
探测的步长变成原来的二次方，探测的下标序列是hash(key)+0, hash(key)+1^2, hash(key)+2^2 ...

双重散列:
使用一组散列函数 hash1(key), hash2(key), hash3(key) ...
先用第一个散列函数，如果位置已被占用，再用第二个散列函数，直到找到空间存储位置

装载因子：表示空位的多少。当散列表中空闲位置不多的时候，散列冲突的概率会大大提高，为了尽可能保证操作效率，会尽可能保证散列表中有一定比例的空闲槽位

散列表的装载因子 = 填入表中的元素个数 / 散列表的长度

**2 链表法**

{% asset_img 36.jpg %}

插入：通过hash函数计算出对应的槽位，插入到对应链表，O(1)
查找, 删除：时间复杂度和链表的长度k成正比


{% asset_img 37.jpg %}

{% asset_img 38.jpg %}

{% asset_img 39.jpg %}

{% asset_img 40.jpg %}

{% asset_img 41.jpg %}


## 树

二叉树、二叉查找树、平衡二叉查找树、红黑树、递归树

节点的高度：节点到叶子节点的最长路径（边数）
节点的深度：根节点到这个节点所经历的边的个数
节点的层数：节点的深度 + 1
树的高度：根节点的高度

{% asset_img 42.jpg %}

满二叉树：叶子节点全在最底层且除叶子节点以外每个节点都有左右两个子节点
完全二叉树：叶子节点都在最底下两层且最后一层的叶子节点都靠左排列，并且除了最后一层，其它层节点个数都要达到最大

### 如何表示（存储）一颗二叉树

链式存储法（略）

基于数组的顺序存储法
把根节点存在下标i=1的位置，左子节点存储在下标2*i的位置，右子节点存储在2*i+1的位置

{% asset_img 42.jpg %}

下标为i/2的位置为父节点的位置

当二叉树不是完全二叉树时，会浪费额外的存储空间

### 二叉树的遍历

{% asset_img 44.jpg %}

## 二叉查找树

树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值

删除操作的三种情况：
1. 要删除的节点没有子节点
2. 要删除的节点有一个子节点：更新父节点，父节点指向删除节点的子节点
3. 要删除的节点有两个子节点：找到删除节点右子树中的最小节点，替换到要删除的节点上，再删除这个最小节点

{% asset_img 45.jpg %}

中序遍历二叉查找树，可以输出有序的数据序列

#### 支持重复数据的二叉查找树

方法一：通过链表和支持动态扩容的数组等结构，把值相同的数据都存储在同一个节点上

方法二：每个节点只存储一个数据，在插入时，如果碰到一个节点的值和要插入数据的值相同，就将这个要插入的数据放到这个节点的右子树，也就是说把这个新插入的数据当做大于这个节点的值来处理

#### 时间复杂度

和树的高度成正比

总节点个数n, 最大层数L
n >= 1+2+4+8+...+2^(L-2)+1
n <= 1+2+4+8+...+2^(L-2)+2^(L-1)
L的范围是[log2(n+1), log2n+1]

### 平衡二叉查找树

平衡二叉树：二叉树中任意一个节点的左右子树的相对高度相差不能大于1

解决普通二叉查找树在频繁的插入、删除等动态更新的情况下，出现时间复杂度退化的问题

### 红黑树

一种不严格的平衡二叉查找树

红黑树需要满足的要求：
- 根节点是黑色的
- 每个叶子节点都是黑色的空节点（主要为了简化实现代码）
- 任何相邻的节点不能都是红色（红色节点是被黑色节点隔开的）
- 每个节点，从该节点到达其叶子节点的所有路径，都包含相同数目的黑色节点


## 堆

堆的要求：
- 堆是一个完全二叉树
- 堆中每一个节点的值都要大于等于（大顶堆）或小于等于（小顶堆）其子树中每个节点的值

### 实现一个堆

#### 存储

数组存储

{% asset_img 46.jpg %}

下标为i的节点的左子节点的下标为i*2，右子节点的下标为i*2+1，父节点的下标为i/2

#### 插入

先插入到堆的末尾，然后再进行（从下向上）堆化

堆化：插入后调整，使堆重新满足堆的要求
顺着节点所在的路径，向上或者向下对比和交换

从下向上的堆化：
{% asset_img 47.jpg %}

#### 删除堆顶元素

删除堆顶元素 --> 删除最大/最小值

将堆的最后一个节点和对顶元素互换，然后删除原堆顶节点，之后再（从上向下）堆化

从下向上的堆化：
{% asset_img 48.jpg %}

堆化的时间复杂度：O(logN）和树的高度成正比

#### 堆排序

1 建堆

两种方法：

1 从前向后处理数组，向堆中依次插入元素，从下向上堆化

2 从后向前处理数组，每个数据从上向下堆化

2 排序

类似删除堆顶元素 
移除堆顶元素后，将下标为n的元素放到堆顶，再通过堆化的方法，将剩下的n-1个元素重新构建成堆
一直重复这个过程，排序完成

{% asset_img 49.jpg %}

时间复杂度：O(nlogn)
不是稳定的排序算法（堆的最后一个节点和堆顶节点互换导致不稳定）

### 堆的应用

优先级队列、TopK、求中位数

#### 优先级队列

1 合并有序小文件

从n个小文件中各取一个元素构成小顶堆，将堆顶元素放入到大文件中并移除
再从小文件取出一个元素放入堆中，重复此过程

2 高性能定时器

将任务按照执行时间为优先级存储到优先级队列中
定时器以队首任务为参考作为等待时间

#### Top K

维护一个大小为K的小顶堆，当新数据到来时和堆顶元素比较，如果比堆顶元素大，则删除堆顶元素，并将这个元素插入堆中；如果比堆顶元素小，则不处理

#### 动态数据求中位数

维护两个堆：一个大顶堆和一个小顶堆
大顶堆存储前半部分数据，小顶堆存储后半部分数据：如果有n个数据，从小到大排序。如果n是偶数，，前n/2个数据存储在大顶堆中，后n/2个数据存储在小顶堆中；如果n是奇数，前n/2+1个数据存储在大顶堆中，后n/2个数据存储在小顶堆中

新加入数据时，如果数据小于等于大顶堆的堆顶元素，则插入到大顶堆；否则插入到小顶堆

插入数据后导致两个堆的数量不符合要求时，进行调整：将小顶堆的堆顶元素移动至大顶堆中

中位数为大顶堆的堆顶元素的数据

{% asset_img 50.jpg %}


## 图

度（degree）：跟顶点相连接的边的条数

有向图：边有方向的图
入度：有多少条边指向这个顶点
出度：有多少条边以这个顶点为起点指向其他顶点

带权图：每条边都有一个权重

### 图的存储

#### 邻接矩阵

使用A[i][j]标记顶点i和j之间的关系
{% asset_img 51.jpg %}

优点：
- 简单直接
- 方便计算

缺点：
- 浪费空间

#### 邻接表

每个顶点对应一条链表，链表里存储指向的顶点
{% asset_img 52.jpg %}

优点：
- 节省空间

缺点：
- 浪费时间

可以改进链表的存储方式


## BFS && DFS

略


## 字符串匹配

### BF: Brute Force

{% asset_img 53.jpg %}

O(n*m)

### RK: Rabin-Karp

对主串中的n-m+1个子串分别求hash值，再逐个与模式串的hash值比较
{% asset_img 54.jpg %}

对于hash算法，可以进行优化
o(n)